{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSMSA53tvvTF"
   },
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7ptoXimXvvTH"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "from scipy import ndimage\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as s_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, UpSampling2D, Flatten, Reshape, Convolution2D\n",
    "from keras.layers import SeparableConv2D, BatchNormalization, LSTM\n",
    "from keras.layers import Average, Concatenate, LeakyReLU, Add, ELU, PReLU, ReLU\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as BE\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.layers import Lambda, Convolution1D,concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras import regularizers\n",
    "# Import Fashion MNIST dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BsyiUw0zvvTM",
    "outputId": "f63b3b46-550a-45ce-d83d-ec62b6fb1bf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "# Scales the training and test data to range between 0 and 1.\n",
    "max_value = float(x_train.max())\n",
    "x_train = x_train.astype('float32') / max_value\n",
    "x_test = x_test.astype('float32') / max_value\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 28, 28, 1))\n",
    "x_test = x_test.reshape((len(x_test), 28, 28, 1))\n",
    "\n",
    "(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "tfLfgyDNvvTT",
    "outputId": "c2685157-9a76-4930-efa4-b788bc749f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder Layers\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
    "\n",
    "# Flatten encoding for visualization\n",
    "autoencoder.add(Flatten())\n",
    "autoencoder.add(Reshape((4, 4, 8)))\n",
    "\n",
    "# Decoder Layers\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "R6C4owv8vvTZ",
    "outputId": "fc0eb504-9432-4080-fd13-812264331b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(\n",
    "    inputs=autoencoder.input, \n",
    "    outputs=autoencoder.get_layer('flatten_1').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3410
    },
    "colab_type": "code",
    "id": "hftWwaX-vvTd",
    "outputId": "17331e79-efa1-4cc1-c9e5-364755765d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3566 - val_loss: 0.3071\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3003 - val_loss: 0.2984\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2946 - val_loss: 0.2948\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.2915 - val_loss: 0.2921\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2892 - val_loss: 0.2903\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2874 - val_loss: 0.2885\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2858 - val_loss: 0.2874\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2844 - val_loss: 0.2858\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2833 - val_loss: 0.2851\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2823 - val_loss: 0.2838\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2814 - val_loss: 0.2831\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2807 - val_loss: 0.2823\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2800 - val_loss: 0.2816\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2793 - val_loss: 0.2810\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2787 - val_loss: 0.2805\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2783 - val_loss: 0.2815\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2777 - val_loss: 0.2796\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2773 - val_loss: 0.2790\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2769 - val_loss: 0.2790\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2766 - val_loss: 0.2784\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2762 - val_loss: 0.2781\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2760 - val_loss: 0.2777\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2757 - val_loss: 0.2777\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2754 - val_loss: 0.2778\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2752 - val_loss: 0.2772\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2750 - val_loss: 0.2769\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2748 - val_loss: 0.2766\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2746 - val_loss: 0.2766\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2744 - val_loss: 0.2764\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2742 - val_loss: 0.2765\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2740 - val_loss: 0.2759\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2738 - val_loss: 0.2758\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2736 - val_loss: 0.2757\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2735 - val_loss: 0.2753\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2733 - val_loss: 0.2752\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2731 - val_loss: 0.2751\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2730 - val_loss: 0.2749\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2729 - val_loss: 0.2748\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2727 - val_loss: 0.2746\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2726 - val_loss: 0.2745\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2725 - val_loss: 0.2744\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2724 - val_loss: 0.2743\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2723 - val_loss: 0.2744\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2722 - val_loss: 0.2741\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2721 - val_loss: 0.2740\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.2720 - val_loss: 0.2740\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2718 - val_loss: 0.2740\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2718 - val_loss: 0.2738\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2717 - val_loss: 0.2737\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2716 - val_loss: 0.2737\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2715 - val_loss: 0.2736\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2715 - val_loss: 0.2735\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2714 - val_loss: 0.2734\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2713 - val_loss: 0.2736\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2713 - val_loss: 0.2736\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2712 - val_loss: 0.2733\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2712 - val_loss: 0.2731\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2711 - val_loss: 0.2731\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2711 - val_loss: 0.2729\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2709 - val_loss: 0.2729\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2709 - val_loss: 0.2733\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2708 - val_loss: 0.2728\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2708 - val_loss: 0.2733\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2708 - val_loss: 0.2728\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2707 - val_loss: 0.2726\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2707 - val_loss: 0.2726\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2706 - val_loss: 0.2725\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2706 - val_loss: 0.2726\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2705 - val_loss: 0.2730\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2704 - val_loss: 0.2727\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2704 - val_loss: 0.2723\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2704 - val_loss: 0.2725\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2703 - val_loss: 0.2723\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2703 - val_loss: 0.2729\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2702 - val_loss: 0.2724\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2702 - val_loss: 0.2723\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2701 - val_loss: 0.2721\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2701 - val_loss: 0.2721\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2701 - val_loss: 0.2723\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2700 - val_loss: 0.2719\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2700 - val_loss: 0.2722\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2699 - val_loss: 0.2720\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2699 - val_loss: 0.2718\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2699 - val_loss: 0.2719\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2698 - val_loss: 0.2730\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2698 - val_loss: 0.2719\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2697 - val_loss: 0.2716\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2697 - val_loss: 0.2716\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2696 - val_loss: 0.2722\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2696 - val_loss: 0.2724\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2696 - val_loss: 0.2717\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2695 - val_loss: 0.2716\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2695 - val_loss: 0.2715\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2694 - val_loss: 0.2716\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2694 - val_loss: 0.2714\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2694 - val_loss: 0.2723\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2694 - val_loss: 0.2713\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2693 - val_loss: 0.2717\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.2692 - val_loss: 0.2713\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2692 - val_loss: 0.2725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcc9b650f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "ZLfL-vhZvvTi",
    "outputId": "988a1464-862a-4e61-a879-38d8c191a2ec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+UAAADnCAYAAAB44/ccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcc9b4dd30>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_test[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(16, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
    "    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6NErcTNvvTm"
   },
   "source": [
    "# 2.\n",
    "## 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gtEyYCCMvvTo",
    "outputId": "827ea492-8b04-4695-9188-8a607d883497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # Only use this if using iPython\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "%matplotlib inline # Only use this if using iPython\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Ka5YRosvvTs",
    "outputId": "b80c1b48-f6be-40f0-8924-e7c9f08a042b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Sid_WdgWvvTx",
    "outputId": "6122150a-e375-41a1-8e7e-0d31ce22cb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "qDhSMVu-vvT2",
    "outputId": "df5b4961-f3cf-4a36-b59b-6c0db94408d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "\n",
    "\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1714
    },
    "colab_type": "code",
    "id": "xz3vXk7MvvT6",
    "outputId": "aaaf5d67-0d8c-458a-baf0-86d6fc80c3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.4201 - acc: 0.8508\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 23s 391us/step - loss: 0.2848 - acc: 0.8963\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.2393 - acc: 0.9120\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.2101 - acc: 0.9216\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 24s 398us/step - loss: 0.1863 - acc: 0.9311\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.1646 - acc: 0.9398\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.1478 - acc: 0.9449\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1336 - acc: 0.9507\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.1212 - acc: 0.9547\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.1113 - acc: 0.9585\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.1032 - acc: 0.9613\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.0949 - acc: 0.9647\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0885 - acc: 0.9670\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.0831 - acc: 0.9686\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.0789 - acc: 0.9704\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.0713 - acc: 0.9732\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.0695 - acc: 0.9742\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0657 - acc: 0.9748\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.0631 - acc: 0.9765\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.0627 - acc: 0.9774\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.0556 - acc: 0.9796\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 23s 387us/step - loss: 0.0566 - acc: 0.9793\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.0537 - acc: 0.9804\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.0534 - acc: 0.9805\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.0506 - acc: 0.9810\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 0.0501 - acc: 0.9816\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 0.0490 - acc: 0.9819\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.0476 - acc: 0.9830\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 25s 410us/step - loss: 0.0462 - acc: 0.9830\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0478 - acc: 0.9828\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.0418 - acc: 0.9852\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0430 - acc: 0.9844\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 0.0384 - acc: 0.9861\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0392 - acc: 0.9857\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0401 - acc: 0.9856\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0407 - acc: 0.9858\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.0369 - acc: 0.9868\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0376 - acc: 0.9870\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 0.0366 - acc: 0.9871\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.0377 - acc: 0.9869\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.0379 - acc: 0.9876\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 25s 408us/step - loss: 0.0344 - acc: 0.9882\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 29s 485us/step - loss: 0.0359 - acc: 0.9878\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0357 - acc: 0.9876\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 25s 413us/step - loss: 0.0349 - acc: 0.9878\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.0347 - acc: 0.9880\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0329 - acc: 0.9887\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 24s 398us/step - loss: 0.0326 - acc: 0.9890\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.0318 - acc: 0.9892\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 23s 386us/step - loss: 0.0320 - acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76f3b4a320>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oN4kr0lgvvT-",
    "outputId": "e3b46950-18ed-4bdf-c56a-c3183e7b26b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6042035289546475\n",
      "Test accuracy: 0.9117\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvu7HthsAfUS"
   },
   "source": [
    "For the Training set, the accuracy of the model with 50 epochs is 0.9892.\n",
    "\n",
    "For the Test set, the accuracy of the model with 50 epochs is 0.9117."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bNuZQ4l5vvUC"
   },
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pPiygw1XvvUU",
    "outputId": "e9e00afd-ea32-4faa-ed02-cc0cb1b5d705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 48, 48, 3)\n",
      "(10000, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "#Reload the data to get a different size\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 784).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 784).astype('float32')\n",
    "x_train=np.dstack([x_train] * 3)\n",
    "x_test=np.dstack([x_test]*3)\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,3).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,3).astype('float32')\n",
    "x_train = np.asarray(\n",
    "    [img_to_array(\n",
    "        array_to_img(im, scale=False).resize((48,48))) for im in x_train])\n",
    "x_test = np.asarray(\n",
    "    [img_to_array(\n",
    "        array_to_img(im, scale=False).resize((48,48))) for im in x_test])\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "id": "2yk3H9g6xaWX",
    "outputId": "eff37ffe-ca62-4707-bca3-ee5e77cbe1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_train = preprocess_input(x_train)\n",
    "x_test  = preprocess_input (x_test)\n",
    "\n",
    "vgg = VGG16(weights='imagenet',include_top=False, input_shape=(48,48,3))\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ffecetluvvUd",
    "outputId": "686dfc93-532a-4482-9e2b-7d9d6eb77aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 66s 1ms/step\n",
      "10000/10000 [==============================] - 11s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_features = vgg.predict(np.array(x_train), batch_size=16, verbose=1)\n",
    "test_features = vgg.predict(np.array(x_test), batch_size=16, verbose=1)\n",
    "train_features_flat = np.reshape(train_features, (60000, 1*1*512))\n",
    "test_features_flat = np.reshape(test_features, (10000, 1*1*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "sjkMdf9h_ZKI",
    "outputId": "ff97bc87-aa68-49e8-9eb9-2a5b94edabae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 267,786\n",
      "Trainable params: 267,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trans_model = Sequential()\n",
    "trans_model.add(Dense(512, activation='relu', input_dim=(512)))\n",
    "trans_model.add(LeakyReLU(alpha=0.1))\n",
    "trans_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "trans_model.compile(\n",
    "    loss='categorical_crossentropy',optimizer=Adam(),metrics=['acc'])\n",
    "\n",
    "trans_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "id": "LH89J2wL_ek9",
    "outputId": "88fcd19e-3dc3-4d81-d601-2704de2965b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 1.3870 - acc: 0.4907\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 1.0454 - acc: 0.6169\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.9522 - acc: 0.6522\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.9069 - acc: 0.6686\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.8862 - acc: 0.6743\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.8684 - acc: 0.6810\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.8488 - acc: 0.6874\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.8315 - acc: 0.6944\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.8208 - acc: 0.6960\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.8124 - acc: 0.7017\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.8042 - acc: 0.7033\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7938 - acc: 0.7066\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7886 - acc: 0.7099\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.7809 - acc: 0.7130\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7748 - acc: 0.7130\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7735 - acc: 0.7157\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7654 - acc: 0.7188\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7598 - acc: 0.7215\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7577 - acc: 0.7209\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7534 - acc: 0.7209\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7504 - acc: 0.7241\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7434 - acc: 0.7267\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.7420 - acc: 0.7256\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7373 - acc: 0.7297\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7313 - acc: 0.7311\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7294 - acc: 0.7312\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7288 - acc: 0.7298\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7287 - acc: 0.7304\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7240 - acc: 0.7314\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7211 - acc: 0.7337\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7187 - acc: 0.7357\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7148 - acc: 0.7370\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.7135 - acc: 0.7360\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7129 - acc: 0.7367\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7072 - acc: 0.7395\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7106 - acc: 0.7383\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7091 - acc: 0.7367\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.7040 - acc: 0.7399\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7073 - acc: 0.7393\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7015 - acc: 0.7423\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7019 - acc: 0.7426\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6967 - acc: 0.7434\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7011 - acc: 0.7414\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6964 - acc: 0.7434\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6939 - acc: 0.7456\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6948 - acc: 0.7429\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6957 - acc: 0.7432\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6920 - acc: 0.7453\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6935 - acc: 0.7439\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.6879 - acc: 0.7463\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6908 - acc: 0.7455\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6912 - acc: 0.7462\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6888 - acc: 0.7473\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6863 - acc: 0.7472\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6820 - acc: 0.7506\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6892 - acc: 0.7469\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6828 - acc: 0.7498\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6797 - acc: 0.7508\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6807 - acc: 0.7491\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.6795 - acc: 0.7514\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6826 - acc: 0.7495\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6798 - acc: 0.7504\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6756 - acc: 0.7523\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6772 - acc: 0.7522\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6751 - acc: 0.7505\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6739 - acc: 0.7518\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6739 - acc: 0.7529\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6742 - acc: 0.7518\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6708 - acc: 0.7535\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6722 - acc: 0.7538\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.6718 - acc: 0.7539\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6694 - acc: 0.7518\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6705 - acc: 0.7536\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6677 - acc: 0.7558\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6676 - acc: 0.7557\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6685 - acc: 0.7560\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6647 - acc: 0.7560\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6666 - acc: 0.7557\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6641 - acc: 0.7557\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6640 - acc: 0.7564\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6631 - acc: 0.7582\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6633 - acc: 0.7559\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6625 - acc: 0.7567\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6627 - acc: 0.7576\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6593 - acc: 0.7581\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6633 - acc: 0.7570\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6570 - acc: 0.7602\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6589 - acc: 0.7584\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.6578 - acc: 0.7583\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6562 - acc: 0.7600\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6562 - acc: 0.7597\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6559 - acc: 0.7604\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6569 - acc: 0.7584\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6548 - acc: 0.7594\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6533 - acc: 0.7621\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6524 - acc: 0.7616\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6517 - acc: 0.7607\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6542 - acc: 0.7599\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6522 - acc: 0.7605\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6486 - acc: 0.7616\n"
     ]
    }
   ],
   "source": [
    "eary_stopping = EarlyStopping(\n",
    "    monitor='loss',min_delta=0,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "transfer_history = trans_model.fit(\n",
    "    train_features_flat,y_train,epochs=100,callbacks=[eary_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "cluAagDqvvUi",
    "outputId": "88472604-60a2-4209-bc9d-440508f26494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.7034361135482788\n",
      "Test accuracy: 0.7509\n"
     ]
    }
   ],
   "source": [
    "score = trans_model.evaluate(test_features_flat, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2yV65yBBwDA"
   },
   "source": [
    "For the Training set, the accuracy of the model with 100 epochs is 0.7616.\n",
    "\n",
    "For the Test set, the accuracy of the model with 50 epochs is 0.7509."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78OioKY4vvUm"
   },
   "source": [
    "# 3\n",
    "# 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g0pRh54qvvUr"
   },
   "outputs": [],
   "source": [
    "with open(\"benign-urls.txt\") as files:\n",
    "    lines = files.readlines()\n",
    "benign_list = [line.rstrip(\"\\n\\r\") for line in lines[0:] if \"#\" not in line]\n",
    "\n",
    "with open(\"malicious-urls.txt\") as files:\n",
    "    lines = files.readlines()\n",
    "malicious_list = [line.rstrip(\"\\n\\r\") for line in lines[0:]]\n",
    "\n",
    "x_train = benign_list + malicious_list\n",
    "y_train = np.concatenate([np.ones(len(benign_list)), np.zeros(len(malicious_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-FO1UKFCvvUx"
   },
   "outputs": [],
   "source": [
    "from string import printable\n",
    "\n",
    "df = pd.DataFrame({'urls':x_train, 'label':y_train}) \n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable] for url in df.urls]\n",
    "\n",
    "max_len=75\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n",
    "Y = np.array(df.label)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "ApE_aCbIvvU0",
    "outputId": "1333ec41-dacc-4dc0-99cb-f7a07c816a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 75, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "47117/47117 [==============================] - 148s 3ms/step - loss: 0.0986 - acc: 0.9795\n",
      "Epoch 2/10\n",
      "47117/47117 [==============================] - 146s 3ms/step - loss: 0.0383 - acc: 0.9835\n",
      "Epoch 3/10\n",
      "47117/47117 [==============================] - 147s 3ms/step - loss: 0.0269 - acc: 0.9867\n",
      "Epoch 4/10\n",
      "47117/47117 [==============================] - 146s 3ms/step - loss: 0.0233 - acc: 0.9891\n",
      "Epoch 5/10\n",
      "47117/47117 [==============================] - 146s 3ms/step - loss: 0.0220 - acc: 0.9898\n",
      "Epoch 6/10\n",
      "47117/47117 [==============================] - 145s 3ms/step - loss: 0.0225 - acc: 0.9888\n",
      "Epoch 7/10\n",
      "47117/47117 [==============================] - 145s 3ms/step - loss: 0.0215 - acc: 0.9897\n",
      "Epoch 8/10\n",
      "47117/47117 [==============================] - 145s 3ms/step - loss: 0.0209 - acc: 0.9900\n",
      "Epoch 9/10\n",
      "47117/47117 [==============================] - 146s 3ms/step - loss: 0.0202 - acc: 0.9900\n",
      "Epoch 10/10\n",
      "47117/47117 [==============================] - 145s 3ms/step - loss: 0.0196 - acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3bbc85da0>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = 5000\n",
    "embedding_vecor_length = 32\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(top_words, embedding_vecor_length, input_length=75))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(lstm_model.summary())\n",
    "\n",
    "eary_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "\n",
    "callbacks = [eary_stopping]\n",
    "\n",
    "lstm_model.fit(x_train, y_train, epochs=10, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Z59Ve4iJvvU4",
    "outputId": "f7cfcbb6-3681-4d2d-e5db-5c85cf6ced21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.019216592526227434\n",
      "Test accuracy: 0.9909874220065366\n"
     ]
    }
   ],
   "source": [
    "score = lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YChPIuYRvvU9"
   },
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1330
    },
    "colab_type": "code",
    "id": "FOq6PlKvvvVC",
    "outputId": "cbcbe5a4-6898-4a88-8fd2-de2d78465eb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=100, output_dim=32, input_length=75, embeddings_regularizer=<keras.reg...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=2, filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=3, filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=4, filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=5, filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization()`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 75, 32)       3200        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 75, 32)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 75, 256)      16640       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 75, 256)      24832       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 75, 256)      33024       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 75, 256)      41216       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 75, 256)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 75, 256)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 75, 256)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 75, 256)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 256)          0           elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 256)          0           elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 256)          0           elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 256)          0           elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256)          0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256)          0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1024)         1049600     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 1024)         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024)         4096        elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1024)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         1049600     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 1024)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            1025        dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,227,329\n",
      "Trainable params: 2,223,233\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "max_len=75\n",
    "emb_dim=32\n",
    "max_vocab_len=100\n",
    "W_reg=regularizers.l2(1e-4)\n",
    "\n",
    "# Input\n",
    "main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "# Embedding layer\n",
    "emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "            W_regularizer=W_reg)(main_input) \n",
    "emb = Dropout(0.25)(emb)\n",
    "\n",
    "\n",
    "def sum_1d(X):\n",
    "    return K.sum(X, axis=1)\n",
    "\n",
    "def get_conv_layer(emb, kernel_size=5, filters=256):\n",
    "    # Conv layer\n",
    "    conv = Convolution1D(kernel_size=kernel_size, filters=filters, \\\n",
    "                 border_mode='same')(emb)\n",
    "    conv = ELU()(conv)\n",
    "\n",
    "    conv = Lambda(sum_1d, output_shape=(filters,))(conv)\n",
    "    #conv = BatchNormalization(mode=0)(conv)\n",
    "    conv = Dropout(0.5)(conv)\n",
    "    return conv\n",
    "\n",
    "conv1 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
    "conv2 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
    "conv3 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
    "conv4 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
    "\n",
    "merged = concatenate([conv1,conv2,conv3,conv4], axis=1)\n",
    "\n",
    "hidden1 = Dense(1024)(merged)\n",
    "hidden1 = ELU()(hidden1)\n",
    "hidden1 = BatchNormalization(mode=0)(hidden1)\n",
    "hidden1 = Dropout(0.5)(hidden1)\n",
    "\n",
    "hidden2 = Dense(1024)(hidden1)\n",
    "hidden2 = ELU()(hidden2)\n",
    "hidden2 = BatchNormalization(mode=0)(hidden2)\n",
    "hidden2 = Dropout(0.5)(hidden2)\n",
    "\n",
    "output = Dense(1, activation='sigmoid', name='output')(hidden2)\n",
    "\n",
    "cnn_model = Model(input=[main_input], output=[output])\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "cnn_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "3pxRKMX-vvVF",
    "outputId": "9baaa416-207d-4b5f-ba79-2c77e97b98a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47117/47117 [==============================] - 18s 388us/step - loss: 0.5110 - acc: 0.7634\n",
      "Epoch 2/20\n",
      "47117/47117 [==============================] - 16s 341us/step - loss: 0.1833 - acc: 0.9482\n",
      "Epoch 3/20\n",
      "47117/47117 [==============================] - 16s 335us/step - loss: 0.1254 - acc: 0.9699\n",
      "Epoch 4/20\n",
      "47117/47117 [==============================] - 16s 334us/step - loss: 0.1121 - acc: 0.9736\n",
      "Epoch 5/20\n",
      "47117/47117 [==============================] - 16s 335us/step - loss: 0.1064 - acc: 0.9743\n",
      "Epoch 6/20\n",
      "47117/47117 [==============================] - 16s 335us/step - loss: 0.0979 - acc: 0.9750\n",
      "Epoch 7/20\n",
      "47117/47117 [==============================] - 16s 334us/step - loss: 0.0884 - acc: 0.9753\n",
      "Epoch 8/20\n",
      "47117/47117 [==============================] - 16s 334us/step - loss: 0.0803 - acc: 0.9764\n",
      "Epoch 9/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0749 - acc: 0.9771\n",
      "Epoch 10/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0707 - acc: 0.9780\n",
      "Epoch 11/20\n",
      "47117/47117 [==============================] - 16s 335us/step - loss: 0.0655 - acc: 0.9786\n",
      "Epoch 12/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0640 - acc: 0.9790\n",
      "Epoch 13/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0587 - acc: 0.9794\n",
      "Epoch 14/20\n",
      "47117/47117 [==============================] - 16s 332us/step - loss: 0.0568 - acc: 0.9808\n",
      "Epoch 15/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0530 - acc: 0.9809\n",
      "Epoch 16/20\n",
      "47117/47117 [==============================] - 16s 334us/step - loss: 0.0485 - acc: 0.9824\n",
      "Epoch 17/20\n",
      "47117/47117 [==============================] - 16s 334us/step - loss: 0.0440 - acc: 0.9838\n",
      "Epoch 18/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0420 - acc: 0.9841\n",
      "Epoch 19/20\n",
      "47117/47117 [==============================] - 16s 332us/step - loss: 0.0422 - acc: 0.9840\n",
      "Epoch 20/20\n",
      "47117/47117 [==============================] - 16s 333us/step - loss: 0.0403 - acc: 0.9836\n",
      "Test loss: 0.024124822271602474\n",
      "Test accuracy: 0.9870753689214619\n"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=callbacks)\n",
    "score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEZXMJSBrzvG"
   },
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "JeY_U_ZkvvVK",
    "outputId": "251228c6-c9fb-470a-a376-39002190d498"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3b51359b0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM and CNN ROC Curve\n",
    "lstm_y_pred_keras = lstm_model.predict(x_test).ravel()\n",
    "lstm_fpr_keras, lstm_tpr_keras, lstm_thresholds_keras = roc_curve(y_test, lstm_y_pred_keras)\n",
    "lstm_auc_keras = auc(lstm_fpr_keras, lstm_tpr_keras)\n",
    "\n",
    "cnn_y_pred_keras = cnn_model.predict(x_test).ravel()\n",
    "cnn_fpr_keras, cnn_tpr_keras, cnn_thresholds_keras = roc_curve(y_test, cnn_y_pred_keras)\n",
    "cnn_auc_keras = auc(cnn_fpr_keras, cnn_tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(lstm_fpr_keras, lstm_tpr_keras, label='LSTM (area = {:.3f})'.format(lstm_auc_keras))\n",
    "plt.plot(cnn_fpr_keras, cnn_tpr_keras, label='CNN (area = {:.3f})'.format(cnn_auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accroding to the ROC curve, each technique get a very high AUC sore and the score for LSTM is a little bit higher."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
